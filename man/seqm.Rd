% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main_functions.R
\name{seqm}
\alias{seqm}
\title{Fitting sequence models}
\usage{
seqm(seqs, response, response_type = "scale", rnn_type = "lstm", K = 20,
  n_hidden = 0, K_hidden = NULL, index_train = NULL, index_valid = NULL,
  max_len = max(sapply(seqs, length)), n_epoch = 20, batch_size = 16,
  optimizer_name = "rmsprop", step_size = 0.001, gpu = TRUE,
  model_output = "seq_model.h5")
}
\arguments{
\item{seqs}{a list of \code{n} action sequences. Each element is an action
sequence in the form of a vector of actions.}

\item{response}{the binary response variable.}

\item{response_type}{"binary" or "scale".}

\item{rnn_type}{the type of recurrent unit to be used for modeling
action sequences. \code{"lstm"} for the long-short term memory unit. 
\code{"gru"} for the gated recurrent unit.}

\item{K}{the latent dimension of the embedding layer and the recurrent layer.}

\item{n_hidden}{the number of hidden fully-connected layers.}

\item{K_hidden}{a vector of length \code{n_hidden} specifying the number of
nodes in each hidden layer.}

\item{index_train, index_valid, index_test}{vectors of indices specifying the
training, validation, and test sets.}

\item{max_len}{the maximum length of sequences.}

\item{n_epoch}{the number of training epochs.}

\item{batch_size}{the batch size used in training.}

\item{optimizer_name}{a character string specifying the optimizer to be used
for training. Availabel options are \code{"sgd"}, \code{"rmsprop"}, 
\code{"adadelta"}, and \code{"adam"}.}

\item{step_size}{the learning rate of optimizer.}

\item{gpu}{logical. If TRUE, use gpu for training if available.}

\item{model_output}{a character string specifying the filename for saving the
trained keras model.}

\item{return_model}{logical. If TRUE, the trained keras model is returned.}
}
\value{
\code{seq2binary} returns a list containing \item{model}{the trained
  keras model.} \item{summary}{a vector of length 3 summarizing the
  prediction accuracy on the training, validation, and test sets.}
  \item{trace}{a \code{n_epoch} by 2 matrix giving the trace of training and
  validation losses in the training process.} \item{pred_train}{the fitted
  probabilities on the training set.} \item{pred_valid}{the predicted
  probabilities for the validation set.} \item{pred_test}{the predicted
  probabilities for the test set.} \item{events}{the set of all possible
  actions.} \item{max_len}{the length of padded sequnces.}
}
\description{
\code{seqm} is used to fit a neural network model relating action sequences
with a response variable.
}
\details{
The model consists of an embedding layer, a recurrent layer and one or more
fully connected layers. The embedding layer takes a action sequence and
output a sequences of \code{K} dimensional numeric vectors to the recurrent
layer. The last output of the recurrent layer is used as the input of the
subsequent fully connected layers. If \code{response_type="binary"}, the last
layer uses the sigmoid activation to produce the probability of the response
being positive. If \code{response_type="scale"}, the last layer uses the linear
activation. The dimension of the output of other fully connected layers
(if any) is specified by \code{K_hidden}.

The action sequences are re-coded into integer sequences and are padded with
zeros to length \code{max_len} before feeding into the model. If the provided
\code{max_len} is smaller than the length of the longest sequence in
\code{seqs}, it will be overridden.
}
\examples{
n <- 50
seqs <- seq_gen(n)
y <- sapply(seqs, function(x) "CHECK_A" \%in\% x)
index_train <- sample(1:n, round(0.8*n))
index_valid <- sample(setdiff(1:n, index_train), round(0.1*n))
index_test <- setdiff(1:n, c(index_train, index_valid))
res <- seq2binary(seqs, y, index_train = index_train, index_valid = index_valid, index_test = index_test)
}
\seealso{
\code{\link{seq_predict}} for prediction from a sequence model.

Other sequence models: \code{\link{seq2binary}},
  \code{\link{seq2scale}}
}
